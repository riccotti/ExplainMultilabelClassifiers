{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import gzip\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "from multilabelexplanations import distance_functions\n",
    "from multilabelexplanations import rules\n",
    "from multilabelexplanations import synthetic_neighborhood\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista dei nomi dei dataset\n",
    "dataset_list = ['yeast', 'diabete', 'woman']\n",
    "\n",
    "#lista contenente i prefissi delle colonne dei dataframe che contengono le classi da predire\n",
    "columns_ylist = ['Class', 'readmitted', 'service']\n",
    "\n",
    "#dizionario con chiave nome del dataset e valore una lista di liste, lista[0] = nomi var continue, lista[1] = nomi var discrete\n",
    "with open('../dataset/dict_names.pickle', 'rb') as handle:\n",
    "    columns_type_dataset = pickle.load(handle)\n",
    "\n",
    "#lista dei nomi delle black box\n",
    "blackbox_list = ['rf', 'svm', 'mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, dataset in enumerate(dataset_list):\n",
    "    \n",
    "    outfile = gzip.open('../output/%s_records.json.gzip' % dataset, 'wb') \n",
    "    \n",
    "    print(datetime.datetime.now(), 'dataset: %s' % dataset)\n",
    "    df_2e = pd.read_csv('../dataset/%s_2e.csv' % dataset)\n",
    "    print('number of instances in the dataset: %s' % len(df_2e))\n",
    "    print()\n",
    "    \n",
    "    cols_Y = [col for col in df_2e.columns if col.startswith(columns_ylist[idx])]\n",
    "    cols_X = [col for col in df_2e.columns if col not in cols_Y]\n",
    "    \n",
    "    X2e = df_2e[cols_X].values\n",
    "    y2e = df_2e[cols_Y].values\n",
    "    \n",
    "    cols_Y_BB = ['BB_'+str(col) for col in cols_Y]\n",
    "    #print(cols_Y_BB)\n",
    "    \n",
    "    for blackbox_name in blackbox_list:\n",
    "        \n",
    "        print(datetime.datetime.now(), '\\tblack box: %s' % blackbox_name)\n",
    "        bb = pickle.load(gzip.open('../models/%s_%s.pickle.gz' % (blackbox_name, dataset), 'rb'))\n",
    "        y_bb = bb.predict(X2e)\n",
    "        \n",
    "        #creo test set con label dati dalla black box (mi dimentico dei label reali)\n",
    "        BB_predictions_df = pd.DataFrame(y_bb,columns=cols_Y_BB)\n",
    "        Xtest_features_df = pd.DataFrame(X2e,columns=cols_X)\n",
    "        #dataframe to explain\n",
    "        X2E = pd.concat([Xtest_features_df,BB_predictions_df],axis=1)\n",
    "        \n",
    "        for instance in range(0,len(X2E)):\n",
    "                        \n",
    "            #istanza da spiegare\n",
    "            i2e = X2E.loc[instance] \n",
    "            i2e_values = i2e[cols_X].values\n",
    "            y_i2e_bb = bb.predict(i2e_values.reshape(1, -1))\n",
    "        \n",
    "            #print(datetime.datetime.now(), '\\tdistance function in feature space, black box: %s' % blackbox_name)\n",
    "            #variabili discrete: le features discrete\n",
    "            #variabili continue: le feature continue\n",
    "            #classi: le classi (target)\n",
    "            X2E_wdistances = distance_functions.sorted_distances_df(X2E,i2e,discrete_var=X2E[columns_type_dataset[dataset][1]].columns.values,continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values,classes_name=X2E[cols_Y_BB].columns.values,label_distance='feat_space_dist')\n",
    "        \n",
    "            #print(datetime.datetime.now(), '\\tdistance function in label space, black box: %s' % blackbox_name)\n",
    "            #variabili discrete: le classi (target)\n",
    "            #variabili continue: nessuna (non conto le features per questa distanza)\n",
    "            #classi: variabili da ignorare presenti nel dataset perchè è otuput dell'applicazione della stessa funzione\n",
    "            X2E_wdistances = distance_functions.sorted_distances_df(X2E_wdistances,i2e,discrete_var=X2E[cols_Y_BB].columns.values, continuous_var=[], classes_name=['feat_space_dist','old_index_feat_space_dist'],label_distance='label_space_dist')\n",
    "        \n",
    "            mixed_discrete = np.append(X2E[columns_type_dataset[dataset][1]].columns.values,X2E[cols_Y_BB].columns.values)        \n",
    "            #print(datetime.datetime.now(), '\\tdistance function in mixed space, black box: %s' % blackbox_name)\n",
    "            #variabili discrete: le features discrete + le classi (target) \n",
    "            #variabili continue: le feature continue\n",
    "            #classi: variabili da ignorare presenti nel dataset perchè è otuput dell'applicazione della stessa funzione\n",
    "            X2E_wdistances = distance_functions.sorted_distances_df(X2E_wdistances,i2e,discrete_var=mixed_discrete,continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values,classes_name=['old_index_label_space_dist','old_index_feat_space_dist','feat_space_dist','label_space_dist'],label_distance='mixed_space_dist')\n",
    "        \n",
    "            filter_old_indexes = [i for i in X2E_wdistances.columns.values if 'index' in i]\n",
    "            k = int(0.5*sqrt(len(X2E_wdistances))) #primi vicini da prendere\n",
    "            size= 1000 #vicini sintetici da generare\n",
    "        \n",
    "            #sample kNN for synthetic neighborhood based on feature space distances\n",
    "            filters_features_space = filter_old_indexes.copy()\n",
    "            filters_features_space.append('label_space_dist') \n",
    "            filters_features_space.append('mixed_space_dist') \n",
    "            sampleKnn_feat_space = X2E_wdistances.drop(filters_features_space,1).sort_values(by='feat_space_dist').reset_index().drop('index',1).loc[0:k]\n",
    "        \n",
    "            #sample kNN for synthetic neighborhood based on label space distances\n",
    "            filters_label_space = filter_old_indexes.copy()\n",
    "            filters_label_space.append('feat_space_dist') \n",
    "            filters_label_space.append('mixed_space_dist') \n",
    "            sampleKnn_label_space = X2E_wdistances.drop(filters_label_space,1).sort_values(by='label_space_dist').reset_index().drop('index',1).loc[0:k]\n",
    "            \n",
    "            #sample kNN for synthetic neighborhood based on mixed space distances\n",
    "            filters_mixed_space = filter_old_indexes.copy()\n",
    "            filters_mixed_space.append('feat_space_dist') \n",
    "            filters_mixed_space.append('label_space_dist') \n",
    "            sampleKnn_mixed_space = X2E_wdistances.drop(filters_mixed_space,1).sort_values(by='mixed_space_dist').reset_index().drop('index',1).loc[0:k]\n",
    "        \n",
    "            #####################################################################################################\n",
    "            #####################################################################################################\n",
    "            ##Creo dataset sintetico n1: unisco il sample dei k primi vicini nello spazio delle feat. e dei label\n",
    "            #print(datetime.datetime.now(), '\\tsynthetic neighborhood alpha/beta, dataset %s, black box: %s' % (dataset, blackbox_name))\n",
    "            # alpha: percentuale di neighbours che voglio dai vicini nello spazio delle features\n",
    "            # beta: percentuale di neighbours che voglio dai vicini nello spazio dei labels\n",
    "            alpha_beta_sample_knn = synthetic_neighborhood.sample_alphaFeat_betaLabel(sampleKnn_feat_space.drop('feat_space_dist',1),sampleKnn_label_space.drop('label_space_dist',1),alpha=0.7,beta=0.3)\n",
    "            synthetic_neighborhood1 = synthetic_neighborhood.random_synthetic_neighborhood_df(alpha_beta_sample_knn,size,discrete_var=X2E[columns_type_dataset[dataset][1]].columns.values,continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values,classes_name=cols_Y_BB)\n",
    "            #uso la black box per assegnare una predizione ad ogni istanza sintetica\n",
    "            BB_label_syn1_df = pd.DataFrame(bb.predict(synthetic_neighborhood1.values),columns=cols_Y_BB)\n",
    "            synthetic_neighborhood1 = pd.concat([synthetic_neighborhood1,BB_label_syn1_df],1)\n",
    "            #####################################################################################################\n",
    "            #faccio crescere un alberto decisionale su questo vicinato sintetico\n",
    "            tree1 = DecisionTreeClassifier()\n",
    "            tree1.fit(synthetic_neighborhood1.drop(cols_Y_BB,1).values,synthetic_neighborhood1[cols_Y_BB].values)\n",
    "            print('____EVALUATION TREE1___ bb: %s' % blackbox_name)\n",
    "            ## evuluating on synthetic neighborhood\n",
    "            y_syn1 = synthetic_neighborhood1[cols_Y_BB].values\n",
    "            y_tree1_syn1 = tree1.predict(synthetic_neighborhood1.drop(cols_Y_BB,1).values)\n",
    "            f1_syn1_tree1 = f1_score(y_true=y_syn1,y_pred=y_tree1_syn1, average='micro')\n",
    "            ## evuluating on real kNN neighborhood used to create the synthetic one\n",
    "            y_samplekNN1 = bb.predict(alpha_beta_sample_knn.drop(cols_Y_BB,1).values)\n",
    "            y_tree1_kNN1 = tree1.predict(alpha_beta_sample_knn.drop(cols_Y_BB,1).values)\n",
    "            f1_kNN1_tree1 = f1_score(y_true=y_samplekNN1,y_pred=y_tree1_kNN1, average='micro')\n",
    "            #hit\n",
    "            y_hit_tree1 = tree1.predict(i2e_values.reshape(1, -1))\n",
    "            hit_jc_tree1 = jaccard_similarity_score(y_i2e_bb,y_hit_tree1)\n",
    "            hit_sm_tree1 = distance_functions.simple_match_distance(y_i2e_bb[0],y_hit_tree1[0])\n",
    "            #rule tree1\n",
    "            rule_tree1,len_rule1 = rules.istance_rule_extractor(i2e_values.reshape(1, -1),tree1,cols_X)\n",
    "            \n",
    "            print('\\t  F1-score tree1 on synthetic neighborhood: %.4f' % f1_syn1_tree1)\n",
    "            print('\\t  F1-score tree1 on kNN sample used to generate synthetic neigh.: %.4f' % f1_kNN1_tree1)\n",
    "            print('\\t \"hit\" of tree1 on i2e[%d], evaluated with the simple match distance: %.4f' % (instance,hit_sm_tree1))\n",
    "            print('\\t \"hit\" of tree1 on i2e[%d], evaluated with the jaccard similarity: %.4f' % (instance,hit_jc_tree1))\n",
    "            print('\\t Decision Rule for i2e, tree 1: %s, lenght: %d' % (str(rule_tree1),len_rule1))\n",
    "            print()\n",
    "            \n",
    "        \n",
    "            #####################################################################################################\n",
    "            #####################################################################################################\n",
    "            ##Creo dataset sintetico n2: uso k i più vicini nello spazio \"misto\" fatto da features e labels\n",
    "            #print(datetime.datetime.now(), '\\tsynthetic neighborhood mixed space, dataset: %s, black box: %s' % (dataset, blackbox_name))\n",
    "            synthetic_neighborhood2 = synthetic_neighborhood.random_synthetic_neighborhood_df(sampleKnn_mixed_space,size,discrete_var=X2E[columns_type_dataset[dataset][1]].columns.values,continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values, classes_name=cols_Y_BB)\n",
    "            #uso la black box per assegnare una predizione ad ogni istanza sintetica\n",
    "            BB_label_syn2_df = pd.DataFrame(bb.predict(synthetic_neighborhood2.values),columns=cols_Y_BB)\n",
    "            synthetic_neighborhood2 = pd.concat([synthetic_neighborhood2,BB_label_syn2_df],1)\n",
    "            #####################################################################################################\n",
    "            #faccio crescere un alberto decisionale su questo vicinato sintetico        \n",
    "            tree2 = DecisionTreeClassifier()\n",
    "            tree2.fit(synthetic_neighborhood2.drop(cols_Y_BB,1).values,synthetic_neighborhood2[cols_Y_BB].values)\n",
    "            print('____EVALUATION TREE2___bb: %s' % blackbox_name)\n",
    "            ## evuluating on synthetic neighborhood\n",
    "            y_syn2 = synthetic_neighborhood2[cols_Y_BB].values\n",
    "            y_tree2_syn2 = tree1.predict(synthetic_neighborhood2.drop(cols_Y_BB,1).values)\n",
    "            f1_syn2_tree2 = f1_score(y_true=y_syn2,y_pred=y_tree2_syn2, average='micro')\n",
    "            ## evuluating on real kNN neighborhood used to create the synthetic one\n",
    "            y_samplekNN2 = bb.predict(sampleKnn_mixed_space.drop(cols_Y_BB,1).drop('mixed_space_dist',1).values)\n",
    "            y_tree2_kNN2 = tree2.predict(sampleKnn_mixed_space.drop(cols_Y_BB,1).drop('mixed_space_dist',1).values)\n",
    "            f1_kNN2_tree2 = f1_score(y_true=y_samplekNN2,y_pred=y_tree2_kNN2, average='micro')\n",
    "            ## hit\n",
    "            y_hit_tree2 = tree2.predict(i2e_values.reshape(1, -1))\n",
    "            hit_jc_tree2 = jaccard_similarity_score(y_i2e_bb,y_hit_tree2)\n",
    "            hit_sm_tree2 = distance_functions.simple_match_distance(y_i2e_bb[0],y_hit_tree2[0])\n",
    "            #rule tree2\n",
    "            rule_tree2,len_rule2 = rules.istance_rule_extractor(i2e_values.reshape(1, -1),tree2,cols_X)\n",
    "        \n",
    "            print('\\t  F1-score tree2 on synthetic neighborhood: %.4f' % f1_syn2_tree2)\n",
    "            print('\\t  F1-score tree1 on kNN sample used to generate synthetic neigh.: %.4f' % f1_kNN2_tree2)\n",
    "            print('\\t \"hit\" of tree1 on i2e[%d], evaluated with the simple match distance: %.4f' % (instance,hit_sm_tree2))\n",
    "            print('\\t \"hit\" of tree1 on i2e[%d], evaluated with the jaccard similarity: %.4f' % (instance,hit_jc_tree2))\n",
    "            print('\\t Decision Rule for i2e, tree 2: %s, lenght: %d' % (str(rule_tree2),len_rule2))\n",
    "            print('---------------------------------------------------------------------------------')\n",
    "     \n",
    "            jrow = {\n",
    "                'dataset_name':dataset,\n",
    "                'bb_name': blackbox_name,\n",
    "                'i2e_id': instance,\n",
    "                'fidelity_tree1_syn':f1_syn1_tree1,\n",
    "                'fidelity_tree1_kNN':f1_kNN1_tree1,\n",
    "                'fidelity_tree2_syn':f1_syn2_tree2,\n",
    "                'fidelity_tree2_kNN':f1_kNN2_tree2,\n",
    "                'i2e_bb_label': y_i2e_bb[0].astype(int).tolist(),\n",
    "                'i2e_tree1_label':y_hit_tree1[0].astype(int).tolist(),\n",
    "                'i2e_tree2_label':y_hit_tree2[0].astype(int).tolist(),\n",
    "                'hit_sm_tree1':hit_sm_tree1,\n",
    "                'hit_jc_tree1':hit_jc_tree1,\n",
    "                'hit_sm_tree2':hit_sm_tree2,\n",
    "                'hit_jc_tree2':hit_jc_tree2,\n",
    "                'rule_tree1':rule_tree1,\n",
    "                'rule_tree2':rule_tree2,\n",
    "                'lenght_rule_tree1':len_rule1,\n",
    "                'lenght_rule_tree2':len_rule2,\n",
    "            }\n",
    "            \n",
    "            json_str = ('%s\\n' % json.dumps(jrow)).encode('utf-8')\n",
    "            outfile.write(json_str)\n",
    "            \n",
    "            if idx % 10 == 0:\n",
    "                print(datetime.datetime.now(), idx)\n",
    "                outfile.flush()\n",
    "                \n",
    "    outfile.close()\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
