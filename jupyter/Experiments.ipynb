{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import gzip\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "from multilabelexplanations import distance_functions\n",
    "from multilabelexplanations import rules\n",
    "from multilabelexplanations import synthetic_neighborhood\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../log'):\n",
    "    os.makedirs('../log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logFormat = '%(asctime)s - pid %(process)d - %(levelname)s -: %(message)s'\n",
    "logFile = '../log/experiments.log'\n",
    "logger = logging.getLogger('checking_experiments_progress')\n",
    "logger.setLevel(logging.INFO)\n",
    "fh = logging.FileHandler(logFile, \"a\")\n",
    "formatter = logging.Formatter(logFormat)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.info('Starting the script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista dei nomi dei dataset\n",
    "dataset = sys.argv[1]\n",
    "blackbox_name = sys.argv[2]\n",
    "\n",
    "#lista contenente i prefissi delle colonne dei dataframe che contengono le classi da predire\n",
    "columns_ylist = {'woman': 'service', 'yeast': 'Class'}\n",
    "\n",
    "#dizionario con chiave nome del dataset e valore una lista di liste, lista[0] = nomi var continue, lista[1] = nomi var discrete\n",
    "with open('../dataset/dict_names.pickle', 'rb') as handle:\n",
    "    columns_type_dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'yeast'\n",
    "blackbox_name = 'rf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_2e = pd.read_csv('../dataset/%s_2e.csv' % dataset)\n",
    "    logger.info('Using dataset %s',dataset)\n",
    "    logger.info('number of instances in the dataset: %s' % len(df_2e))\n",
    "except Exception:\n",
    "    logger.exception(\"Problem in loading the dataset\")\n",
    "\n",
    "cols_Y = [col for col in df_2e.columns if col.startswith(columns_ylist[dataset])]\n",
    "cols_X = [col for col in df_2e.columns if col not in cols_Y]\n",
    "\n",
    "X2e = df_2e[cols_X].values\n",
    "cols_Y_BB = ['BB_'+str(col) for col in cols_Y]\n",
    " \n",
    "logger.info('Using black box: %s' % blackbox_name)    \n",
    "try:\n",
    "    bb = pickle.load(gzip.open('../models/tuned_%s_%s.pickle.gz' % (blackbox_name, dataset), 'rb'))\n",
    "except Exception:\n",
    "    logger.exception(\"Problem loading the model\")\n",
    "    \n",
    "try:\n",
    "    y_bb = bb.predict(X2e)\n",
    "except Exception:\n",
    "    logger.exception(\"Problem with trained model, probably features do not match those used to train the model\")\n",
    "    \n",
    "#Creating the dataset to be explained X2E\n",
    "BB_predictions_df = pd.DataFrame(y_bb,columns=cols_Y_BB)\n",
    "Xtest_features_df = pd.DataFrame(X2e,columns=cols_X)\n",
    "X2E = pd.concat([Xtest_features_df,BB_predictions_df],axis=1)\n",
    "X2E_len = len(X2E)\n",
    "instance_counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info('Going into the loop over all instances to explain')\n",
    "\n",
    "for instance in X2E.index.values:\n",
    "    instance_counter+=1\n",
    "    logger.info('explainig instance %d, %d out of %d' % (instance,instance_counter, X2E_len))\n",
    "    \n",
    "    #instance to be explained\n",
    "    i2e = X2E.loc[instance] \n",
    "    i2e_values = i2e[cols_X].values\n",
    "    y_i2e_bb = bb.predict(i2e_values.reshape(1, -1))\n",
    "\n",
    "    logger.info('computing pairwise distances using distance_functions.sorted_distances_df')\n",
    "    X2E_wdistances = distance_functions.sorted_distances_df(\n",
    "        X2E,i2e,discrete_var=X2E[columns_type_dataset[dataset][1]].columns.values,\n",
    "        continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values,\n",
    "        classes_name=X2E[cols_Y_BB].columns.values,label_distance='feat_space_dist')\n",
    "    X2E_wdistances = distance_functions.sorted_distances_df(\n",
    "        X2E_wdistances,i2e,discrete_var=X2E[cols_Y_BB].columns.values, \n",
    "        continuous_var=[], classes_name=['feat_space_dist','old_index_feat_space_dist'],label_distance='label_space_dist')\n",
    "\n",
    "    mixed_discrete = np.append(X2E[columns_type_dataset[dataset][1]].columns.values,X2E[cols_Y_BB].columns.values)        \n",
    "    X2E_wdistances = distance_functions.sorted_distances_df(\n",
    "        X2E_wdistances,i2e,discrete_var=mixed_discrete,\n",
    "        continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values,\n",
    "        classes_name=['old_index_label_space_dist','old_index_feat_space_dist','feat_space_dist',\n",
    "                      'label_space_dist'],label_distance='mixed_space_dist')\n",
    "    filter_old_indexes = [i for i in X2E_wdistances.columns.values if 'index' in i]\n",
    "    \n",
    "    #number of real neighbors to consider:\n",
    "    k = int(0.5*np.sqrt(len(X2E_wdistances))) \n",
    "    #number of synthetic neighbors to generate\n",
    "    size= 1000 \n",
    "\n",
    "    logger.info('sampling %d real neighbors for synthetic neighborhood generation' % k)\n",
    "    #sample kNN for synthetic neighborhood based on feature space distances\n",
    "    filters_features_space = filter_old_indexes.copy()\n",
    "    filters_features_space.append('label_space_dist') \n",
    "    filters_features_space.append('mixed_space_dist') \n",
    "    sampleKnn_feat_space = X2E_wdistances.drop(\n",
    "        filters_features_space,1).sort_values(by='feat_space_dist').reset_index().drop('index',1).loc[0:k]\n",
    "\n",
    "    #sample kNN for synthetic neighborhood based on label space distances\n",
    "    filters_label_space = filter_old_indexes.copy()\n",
    "    filters_label_space.append('feat_space_dist') \n",
    "    filters_label_space.append('mixed_space_dist') \n",
    "    sampleKnn_label_space = X2E_wdistances.drop(\n",
    "        filters_label_space,1).sort_values(by='label_space_dist').reset_index().drop('index',1).loc[0:k]\n",
    "\n",
    "    #sample kNN for synthetic neighborhood based on mixed space distances\n",
    "    filters_mixed_space = filter_old_indexes.copy()\n",
    "    filters_mixed_space.append('feat_space_dist') \n",
    "    filters_mixed_space.append('label_space_dist') \n",
    "    sampleKnn_mixed_space = X2E_wdistances.drop(\n",
    "        filters_mixed_space,1).sort_values(by='mixed_space_dist').reset_index().drop('index',1).loc[0:k]\n",
    "\n",
    "    #####################################################################################################\n",
    "    ###############################MIXED NEIGHBORHOOD####################################################\n",
    "\n",
    "    logger.info('generating MIXED synthetic neighborhood')\n",
    "    alpha_beta_sample_knn = synthetic_neighborhood.sample_alphaFeat_betaLabel(\n",
    "        sampleKnn_feat_space.drop('feat_space_dist',1),\n",
    "        sampleKnn_label_space.drop('label_space_dist',1),\n",
    "        alpha=0.7,beta=0.3)\n",
    "    synthetic_neighborhood1 = synthetic_neighborhood.random_synthetic_neighborhood_df(\n",
    "        alpha_beta_sample_knn,size,\n",
    "        discrete_var=X2E[columns_type_dataset[dataset][1]].columns.values,\n",
    "        continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values,\n",
    "        classes_name=cols_Y_BB)\n",
    "    BB_label_syn1_df = pd.DataFrame(bb.predict(synthetic_neighborhood1.values),columns=cols_Y_BB)\n",
    "    synthetic_neighborhood1 = pd.concat([synthetic_neighborhood1,BB_label_syn1_df],1)\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #faccio crescere un alberto decisionale su questo vicinato sintetico\n",
    "    logger.info('growing DT on MIXED synthetic neighborhood')\n",
    "    tree1 = DecisionTreeClassifier()\n",
    "    tree1.fit(synthetic_neighborhood1.drop(cols_Y_BB,1).values,synthetic_neighborhood1[cols_Y_BB].values)\n",
    "    #print('____EVALUATION TREE1___ bb: %s' % blackbox_name)\n",
    "    ## evuluating on synthetic neighborhood\n",
    "    y_syn1 = synthetic_neighborhood1[cols_Y_BB].values\n",
    "    y_tree1_syn1 = tree1.predict(synthetic_neighborhood1.drop(cols_Y_BB,1).values)\n",
    "    f1_syn1_tree1 = f1_score(y_true=y_syn1,y_pred=y_tree1_syn1, average='micro')\n",
    "    ## evuluating on real kNN neighborhood used to create the synthetic one\n",
    "    y_samplekNN1 = bb.predict(alpha_beta_sample_knn.drop(cols_Y_BB,1).values)\n",
    "    y_tree1_kNN1 = tree1.predict(alpha_beta_sample_knn.drop(cols_Y_BB,1).values)\n",
    "    f1_kNN1_tree1 = f1_score(y_true=y_samplekNN1,y_pred=y_tree1_kNN1, average='micro')\n",
    "    #hit\n",
    "    y_hit_tree1 = tree1.predict(i2e_values.reshape(1, -1))\n",
    "    hit_jc_tree1 = jaccard_similarity_score(y_i2e_bb,y_hit_tree1)\n",
    "    hit_sm_tree1 = distance_functions.simple_match_distance(y_i2e_bb[0],y_hit_tree1[0])\n",
    "    #rule tree1\n",
    "    rule_tree1,len_rule1 = rules.istance_rule_extractor(i2e_values.reshape(1, -1),tree1,cols_X)\n",
    "\n",
    "    #####################################################################################################\n",
    "    #################################UNIFIED NEIGHBORHOOD################################################\n",
    "\n",
    "    \n",
    "    logger.info('generating UNIFIED synthetic neighborhood')\n",
    "    synthetic_neighborhood2 = synthetic_neighborhood.random_synthetic_neighborhood_df(\n",
    "        sampleKnn_mixed_space,size,discrete_var=X2E[columns_type_dataset[dataset][1]].columns.values,\n",
    "        continuous_var=X2E[columns_type_dataset[dataset][0]].columns.values, classes_name=cols_Y_BB)\n",
    "    #uso la black box per assegnare una predizione ad ogni istanza sintetica\n",
    "    BB_label_syn2_df = pd.DataFrame(bb.predict(synthetic_neighborhood2.values),columns=cols_Y_BB)\n",
    "    synthetic_neighborhood2 = pd.concat([synthetic_neighborhood2,BB_label_syn2_df],1)\n",
    "    #####################################################################################################\n",
    "    #faccio crescere un alberto decisionale su questo vicinato sintetico        \n",
    "    logger.info('growing DT on UNIFIED synthetic neighborhood')\n",
    "    tree2 = DecisionTreeClassifier()\n",
    "    tree2.fit(synthetic_neighborhood2.drop(cols_Y_BB,1).values,synthetic_neighborhood2[cols_Y_BB].values)\n",
    "    #print('____EVALUATION TREE2___bb: %s' % blackbox_name)\n",
    "    ## evuluating on synthetic neighborhood\n",
    "    y_syn2 = synthetic_neighborhood2[cols_Y_BB].values\n",
    "    y_tree2_syn2 = tree1.predict(synthetic_neighborhood2.drop(cols_Y_BB,1).values)\n",
    "    f1_syn2_tree2 = f1_score(y_true=y_syn2,y_pred=y_tree2_syn2, average='micro')\n",
    "    ## evuluating on real kNN neighborhood used to create the synthetic one\n",
    "    y_samplekNN2 = bb.predict(sampleKnn_mixed_space.drop(cols_Y_BB,1).drop('mixed_space_dist',1).values)\n",
    "    y_tree2_kNN2 = tree2.predict(sampleKnn_mixed_space.drop(cols_Y_BB,1).drop('mixed_space_dist',1).values)\n",
    "    f1_kNN2_tree2 = f1_score(y_true=y_samplekNN2,y_pred=y_tree2_kNN2, average='micro')\n",
    "    ## hit\n",
    "    y_hit_tree2 = tree2.predict(i2e_values.reshape(1, -1))\n",
    "    hit_jc_tree2 = jaccard_similarity_score(y_i2e_bb,y_hit_tree2)\n",
    "    hit_sm_tree2 = distance_functions.simple_match_distance(y_i2e_bb[0],y_hit_tree2[0])\n",
    "    #rule tree2\n",
    "    rule_tree2,len_rule2 = rules.istance_rule_extractor(i2e_values.reshape(1, -1),tree2,cols_X)\n",
    "\n",
    "\n",
    "    jrow = {\n",
    "        'dataset_name':dataset,\n",
    "        'bb_name': blackbox_name,\n",
    "        'i2e_id': str(instance),\n",
    "        'fidelity_tree1_syn':f1_syn1_tree1,\n",
    "        'fidelity_tree1_kNN':f1_kNN1_tree1,\n",
    "        'fidelity_tree2_syn':f1_syn2_tree2,\n",
    "        'fidelity_tree2_kNN':f1_kNN2_tree2,\n",
    "        'i2e_bb_label': y_i2e_bb[0].astype(int).tolist(),\n",
    "        'i2e_tree1_label':y_hit_tree1[0].astype(int).tolist(),\n",
    "        'i2e_tree2_label':y_hit_tree2[0].astype(int).tolist(),\n",
    "        'hit_sm_tree1':hit_sm_tree1,\n",
    "        'hit_jc_tree1':hit_jc_tree1,\n",
    "        'hit_sm_tree2':hit_sm_tree2,\n",
    "        'hit_jc_tree2':hit_jc_tree2,\n",
    "        'rule_tree1':rule_tree1,\n",
    "        'rule_tree2':rule_tree2,\n",
    "        'lenght_rule_tree1':len_rule1,\n",
    "        'lenght_rule_tree2':len_rule2,\n",
    "    }\n",
    "    \n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    try:\n",
    "        json_str = ('%s\\n' % json.dumps(jrow)).encode('utf-8')\n",
    "    except Exception:\n",
    "        logger.exception('Problems in dumping row')\n",
    "        break\n",
    "    try:\n",
    "        with gzip.GzipFile('../output/%s_%s_%s_explanationsandmetrics.json.gz' % (now, dataset, blackbox_name), 'a') as fout:\n",
    "            fout.write(json_str)\n",
    "    except Exception:\n",
    "        logger.exception('Problems in saving the output')\n",
    "        break \n",
    "    logging.info(' ')\n",
    "logging.info('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
