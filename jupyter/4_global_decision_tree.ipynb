{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from multilabelexplanations import distance_functions\n",
    "from multilabelexplanations import rules\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_ylist = {'woman': 'service', 'yeast': 'Class', 'medical':'Class'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ['yeast', 'woman','medical']\n",
    "blackbox_list = ['rf', 'svm', 'mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50, 70, 80, 90, 100],\n",
    "    'min_samples_split': [2**i for i in range(1, 10)],\n",
    "    'min_samples_leaf': [2**i for i in range(1, 10)],\n",
    "}\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ['medical']\n",
    "blackbox_list = ['rf', 'svm', 'mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dataset medical_2e.csv\n",
      "F1 score (fidelity) su X2E: 0.908\n",
      "F1 score (fidelity) su X2E: 0.936\n",
      "F1 score (fidelity) su X2E: 0.861\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_list:\n",
    "    print('using dataset %s_2e.csv' % dataset)\n",
    "    df_2e = pd.read_csv('../dataset/%s_2e.csv' % dataset)\n",
    "    cols_Y = [col for col in df_2e.columns if col.startswith(columns_ylist[dataset])]\n",
    "    cols_X = [col for col in df_2e.columns if col not in cols_Y]\n",
    "\n",
    "    X2e = df_2e[cols_X].values\n",
    "    y2e = df_2e[cols_Y].values\n",
    "\n",
    "    for blackbox_name in blackbox_list:\n",
    "        bb = pickle.load(gzip.open('../models/tuned_%s_%s.pickle.gz' % (blackbox_name, dataset), 'rb'))\n",
    "        bb_labels = bb.predict(X2e)\n",
    "        \n",
    "        #traino un GDT facendo tuning degli iperparametri\n",
    "        dt = DecisionTreeClassifier()\n",
    "        sop = np.prod([len(v) for k, v in dt_params.items()])\n",
    "        n_iter_search = min(100, sop)\n",
    "        random_search = RandomizedSearchCV(dt, param_distributions=dt_params,scoring='f1_micro', n_iter=n_iter_search, cv=cv)\n",
    "        random_search.fit(X2e, bb_labels)\n",
    "        best_params = random_search.best_params_\n",
    "        dt.set_params(**best_params)\n",
    "        #fitto il GDT sul dataset\n",
    "        dt.fit(X2e, bb_labels)\n",
    "        GDT_labels = dt.predict(X2e)\n",
    "        print('F1 score (fidelity) su X2E: %.3f' % f1_score(bb_labels, GDT_labels, average='micro'))\n",
    "        #salvo il modello GDT fittato\n",
    "        joblib.dump(dt, '../global_dt/GDT_to_mimic_%s_%s.pkl' % (blackbox_name, dataset)) \n",
    "        \n",
    "        for id_i2e,i2e in enumerate(X2e):\n",
    "            rule, len_rule = rules.istance_rule_extractor(i2e.reshape(1, -1),dt,cols_X)\n",
    "            jrow = {\n",
    "                'dataset_name':dataset,\n",
    "                'bb_name': blackbox_name,\n",
    "                'i2e_id': str(id_i2e),\n",
    "                'i2e_bb_label': bb_labels[id_i2e].astype(int).tolist(),\n",
    "                'i2e_GDT_label': GDT_labels[id_i2e].astype(int).tolist(),\n",
    "                'hit_sm':distance_functions.simple_match_distance(bb_labels[id_i2e],GDT_labels[id_i2e]),\n",
    "                'hit_jc':jaccard_similarity_score(bb_labels[id_i2e],GDT_labels[id_i2e]),\n",
    "                'rule':rule,\n",
    "                'len_rule':str(len_rule),\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                json_str = ('%s\\n' % json.dumps(jrow)).encode('utf-8')\n",
    "            except Exception as e:\n",
    "                print('Problems in dumping row: '+e)\n",
    "                break\n",
    "            try:\n",
    "                with gzip.GzipFile('../global_dt/GDT_to_mimic_%s_%s_metrics.json.gz' % (dataset, blackbox_name), 'a') as fout:\n",
    "                    fout.write(json_str)\n",
    "            except Exception as e:\n",
    "                print('Problems in saving the output: '+e)\n",
    "                break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
